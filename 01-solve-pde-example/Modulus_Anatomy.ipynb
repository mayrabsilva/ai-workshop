{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Workflow for Modulus Projects\n",
    "\n",
    "1. Initialize Hydra using the Modulus main decorator to read in the configuration YAML.\n",
    "\n",
    "2. Load necessary data if needed or define the geometry of the system if needed.\n",
    "\n",
    "3. Create any Nodes required, such as your neural network model.\n",
    "\n",
    "4. Create a training domain object.\n",
    "\n",
    "5. Create constraints and add each to the domain.\n",
    "\n",
    "6. Create any inferencers, validators or monitors needed.\n",
    "\n",
    "7. Initialize a solver with the populated training domain.\n",
    "\n",
    "8. Run the solver, beginning optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of approximating a solution to given differential equation and boundary conditions with Modulus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Hydra\n",
    "\n",
    "[Hydra configuration package](https://docs.nvidia.com/deeplearning/modulus/user_guide/features/configuration.html) is built into the heart of Modulus. It allows the easy control over various hyperparameters using YAML files. In Modulus, Hydra is the first component to be initialized, and it has direct influence on all component levels inside of Modulus.\n",
    "\n",
    "Here is the content of config.yaml file:\n",
    "\n",
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 200\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "training:\n",
    "  rec_results_freq : 1000\n",
    "  rec_constraint_freq: 1000\n",
    "  max_steps : 5000\n",
    "```\n",
    "You can use the config file to change a variety of training parameters like the learning rate, optimizer, decay_rate, decay_steps, etc. The results saveing frequency, constraints saving frequency and max_steps can also be defined. The modulus_default configs setting is used here you can also define more custom configs as well.\n",
    "\n",
    "For running Modulus in Jupyter notebook, we can load config with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modulus\n",
    "from modulus.sym.hydra import to_yaml\n",
    "from modulus.sym.hydra.utils import compose\n",
    "from modulus.sym.hydra.config import ModulusConfig\n",
    "\n",
    "cfg = compose(config_path=\"./\", config_name=\"config\")\n",
    "cfg.network_dir = 'outputs'    # Set the network directory for checkpoints\n",
    "print(to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the Geometry\n",
    "\n",
    "For this purely physics case, there is no external training data. Instead, Instead, we will create some geometry that will be used to sample various collocation points to impose the  PDE loss and boundary loss. Modulus has several geometry objects including 1D shapes like `Point1D` and `Line1D` and 3D shapes like `Torus`, `Tetrahedron` etc. Here, we use the `Line1D` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol\n",
    "from modulus.sym.geometry.primitives_1d import Line1D\n",
    "\n",
    "# make geometry\n",
    "x = Symbol(\"x\")\n",
    "geo = Line1D(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the geometry object has been instantiated, you can sample the points in that geometry object using methods like [`sample_boundary`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.geometry.html#modulus.geometry.geometry.Geometry.sample_boundary) and [`sample_interior`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.geometry.html#modulus.geometry.geometry.Geometry.sample_interior) to see what is being sampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = geo.sample_boundary(5)\n",
    "print(\"Boundary Samples\", samples)\n",
    "\n",
    "samples = geo.sample_interior(5)\n",
    "print(\"Interior Samples\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Nodes\n",
    "Before setting up the nodes, let's first define the PDE for this problem. For this simple problem, a simple PDE can be set up as below. Modulus also contains several common pre-defined PDEs to choose from, such as Navier-Stokes, Linear Elasticity, Advection Diffusion, Wave Equations, etc.\n",
    "\n",
    "The PDE class enables us to write equations symbolically in SymPy, so that we can quickly write equations in the most natural way. The SymPy equations are converted to PyTorch expressions in the back-end and can also be printed out to ensure correct implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol, Number, Function\n",
    "from modulus.sym.eq.pde import PDE\n",
    "\n",
    "class CustomPDE(PDE):\n",
    "    def __init__(self, f=1.0):\n",
    "        # coordinates\n",
    "        x = Symbol(\"x\")\n",
    "\n",
    "        # make input variables\n",
    "        input_variables = {\"x\": x}\n",
    "\n",
    "        # make u function\n",
    "        u = Function(\"u\")(*input_variables)\n",
    "\n",
    "        # source term\n",
    "        if type(f) is str:\n",
    "            f = Function(f)(*input_variables)\n",
    "        elif type(f) in [float, int]:\n",
    "            f = Number(f)\n",
    "\n",
    "        # set equations\n",
    "        self.equations = {}\n",
    "        self.equations[\"custom_pde\"] = (\n",
    "            u.diff(x, 2) - f\n",
    "        )  # \"custom_pde\" key name will be used in constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create the nodes required for our problem. The word \"nodes\" here doesn't mean \"compute nodes\" or \"login nodes\" you might be familiar with in high-performance computing (HPC) environments. Instead, nodes in Modulus are used to represent components that will be executed in the forward pass during the training. These include the neural network itself and any equations used to formulate the PDE loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.models.fully_connected import FullyConnectedArch\n",
    "from modulus.sym.key import Key\n",
    "\n",
    "eq = CustomPDE(f=1.0)\n",
    "\n",
    "# Define fully connected neural network with 3 layers and 32 neurons in each layer. Takes \"x\" as input variable, \"u\" as input variable\n",
    "\n",
    "u_net = FullyConnectedArch(\n",
    "    input_keys=[Key(\"x\")], output_keys=[Key(\"u\")], nr_layers=3, layer_size=32\n",
    ")\n",
    "\n",
    "nodes = eq.make_nodes() + [u_net.make_node(name=\"u_network\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a training domain object\n",
    "\n",
    "The `Domain` includes constraints (such as geometric areas or volumes within which the equations of the problem are solved and the equations governing the physical phenomena, and boundary conditions) and additional components (such as inferencers, validators, and monitors) needed in the training process. Once user defins constraints, they are added to the Domain to create a collection of training objectives. Then, Domain and the configs are passed to neural network as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.domain import Domain\n",
    "\n",
    "# make domain\n",
    "domain = Domain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this physics-driven problem, constraints are the boundary conditions and equation residuals (\"residuals\" refer to the difference between the outputs of the neural network and the exact values dictated by the governing physical equations). Our goal is to satisfy the boundary conditions exactly, and ideally make the PDE residuals go to 0. Constraints can be specified using classes like [`PointwiseBoundaryConstrant`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.domain.constraint.html#modulus.domain.constraint.continuous.PointwiseBoundaryConstraint) and [`PointwiseInteriorConstraint`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.domain.constraint.html#modulus.domain.constraint.continuous.PointwiseInteriorConstraint). Later, a loss function (by default L2) will be generated based on these constraints and minimized by the optimizer.\n",
    "\n",
    "To generate boundary conditions, we need to sample the points on the boundary/surface of our geometry, specify the nodes we would like to evaluate on these points, and then assign values to them as needed.\n",
    "\n",
    "To generate a boundary condition, PointwiseBoundaryConstraint class will sample the entire boundary of our geometry, i.e. both endpoints of the 1D line. \n",
    "\n",
    "To solve the PDE equation we defined, PointwiseInteriorConstraint class will sample points in the interior of the geometry and the PDE is enforced on all the points in the interior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.domain.constraint import PointwiseBoundaryConstraint, PointwiseInteriorConstraint\n",
    "\n",
    "# bcs\n",
    "bc = PointwiseBoundaryConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=geo,\n",
    "    outvar={\"u\": 0},   # the desired values of the boundary condition\n",
    "    batch_size=2,      # the number of points to sample on each boundary\n",
    ")\n",
    "domain.add_constraint(bc, \"bc\")\n",
    "\n",
    "# interior\n",
    "interior = PointwiseInteriorConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=geo,\n",
    "    outvar={\"custom_pde\": 0},   # the desired solution of the PDE \n",
    "    batch_size=100,  \n",
    "    bounds={x: (0, 1)},   # the range for sampling the values for variables\n",
    ")\n",
    "domain.add_constraint(interior, \"interior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create any Inferencers, Validators or Monitors\n",
    "\n",
    "Here, we will create an inferencer to visualize results. It will provide the predicted value of the output variable \"u\" for 100 linearly spaced points in the range [0, 1] of the input variable \"x\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from modulus.sym.domain.inferencer import PointwiseInferencer\n",
    "\n",
    "# add inferencer\n",
    "inference = PointwiseInferencer(\n",
    "    nodes=nodes,\n",
    "    invar={\"x\": np.linspace(0, 1.0, 100).reshape(-1,1)},\n",
    "    output_names=[\"u\"],\n",
    ")\n",
    "domain.add_inferencer(inference, \"inf_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Initialize and Run a Solver:\n",
    "Here, we will initialize a solver with the Domain we just created and other configurations that define the optimizer choices using Solver class. Then, run the solver, begining optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the logging work in the jupyter cells\n",
    "# execute this cell only once\n",
    "import logging\n",
    "logging.getLogger().addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from modulus.sym.solver import Solver\n",
    "\n",
    "# optional set appropriate GPU in case of multi-GPU machine\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "# make solver\n",
    "slv = Solver(cfg, domain)\n",
    "\n",
    "# start solver\n",
    "slv.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualizing the Results\n",
    "\n",
    "The results can be plotted with `matplotlib`. The inferencer/validator writes the data to disk which we will use to make the plots. The output format can be modified in the `save_filetypes` in config.yaml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = np.load('./outputs/inferencers/inf_data.npz', allow_pickle=True)\n",
    "data = np.atleast_1d(data.f.arr_0)[0]\n",
    "plt.figure()\n",
    "x = data['x'].flatten()\n",
    "pred_u = data['u'].flatten()\n",
    "plt.plot(np.sort(x), pred_u[np.argsort(x)], label='Neural Solver')\n",
    "plt.plot(np.sort(x), 0.5*(np.sort(x)*(np.sort(x)-1)), label='(1/2)(x-1)x')\n",
    "x_np = np.array([0., 1.])\n",
    "u_np = 0.5*(x_np-1)*x_np\n",
    "plt.scatter(x_np, u_np, label='BC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish! Well down!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Modulus-24.01",
   "language": "python",
   "name": "modulus-24.01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
